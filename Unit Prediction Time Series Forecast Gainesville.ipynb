{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95409a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8423b9d-cbd1-442f-91b9-bfacac5859d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit</th>\n",
       "      <th>Call Type</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Nature of Call</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date of Service</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>MEDIC 201</td>\n",
       "      <td>BLS</td>\n",
       "      <td>PRIORITY 2 - IMMEDIATE</td>\n",
       "      <td>Transfer/Interfacility/Palliative Care</td>\n",
       "      <td>JACKSONVILLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>MEDIC 201</td>\n",
       "      <td>BLS</td>\n",
       "      <td>PRIORITY 3</td>\n",
       "      <td>Psychiatric Problem/Abnormal Behavior/Suicide ...</td>\n",
       "      <td>JACKSONVILLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>MEDIC 208</td>\n",
       "      <td>BLS</td>\n",
       "      <td>PRIORITY 4</td>\n",
       "      <td>Discharge</td>\n",
       "      <td>BELLAIR-MEADOWBROOK TERRACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>MEDIC 208</td>\n",
       "      <td>BLS</td>\n",
       "      <td>PRIORITY 4</td>\n",
       "      <td>Discharge</td>\n",
       "      <td>BELLAIR-MEADOWBROOK TERRACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>MEDIC 201</td>\n",
       "      <td>BLS</td>\n",
       "      <td>PRIORITY 4</td>\n",
       "      <td>Discharge</td>\n",
       "      <td>BELLAIR-MEADOWBROOK TERRACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-21</th>\n",
       "      <td>MEDIC 203</td>\n",
       "      <td>BLS</td>\n",
       "      <td>PRIORITY 4</td>\n",
       "      <td>Transfer/Interfacility/Palliative Care</td>\n",
       "      <td>JACKSONVILLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-21</th>\n",
       "      <td>MEDIC 201</td>\n",
       "      <td>BLS</td>\n",
       "      <td>PRIORITY 4</td>\n",
       "      <td>Discharge</td>\n",
       "      <td>BELLAIR-MEADOWBROOK TERRACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-21</th>\n",
       "      <td>MEDIC 203</td>\n",
       "      <td>BLS</td>\n",
       "      <td>PRIORITY 4</td>\n",
       "      <td>Discharge</td>\n",
       "      <td>BELLAIR-MEADOWBROOK TERRACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-21</th>\n",
       "      <td>MEDIC 204</td>\n",
       "      <td>BLS</td>\n",
       "      <td>PRIORITY 4</td>\n",
       "      <td>Discharge</td>\n",
       "      <td>JACKSONVILLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-21</th>\n",
       "      <td>MEDIC 202</td>\n",
       "      <td>BLS</td>\n",
       "      <td>PRIORITY 3</td>\n",
       "      <td>Transfer/Interfacility/Palliative Care</td>\n",
       "      <td>JACKSONVILLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3637 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Unit Call Type                Priority  \\\n",
       "Date of Service                                                \n",
       "2022-12-01       MEDIC 201       BLS  PRIORITY 2 - IMMEDIATE   \n",
       "2022-12-01       MEDIC 201       BLS              PRIORITY 3   \n",
       "2022-12-01       MEDIC 208       BLS              PRIORITY 4   \n",
       "2022-12-01       MEDIC 208       BLS              PRIORITY 4   \n",
       "2022-12-01       MEDIC 201       BLS              PRIORITY 4   \n",
       "...                    ...       ...                     ...   \n",
       "2023-12-21       MEDIC 203       BLS              PRIORITY 4   \n",
       "2023-12-21       MEDIC 201       BLS              PRIORITY 4   \n",
       "2023-12-21       MEDIC 203       BLS              PRIORITY 4   \n",
       "2023-12-21       MEDIC 204       BLS              PRIORITY 4   \n",
       "2023-12-21       MEDIC 202       BLS              PRIORITY 3   \n",
       "\n",
       "                                                    Nature of Call  \\\n",
       "Date of Service                                                      \n",
       "2022-12-01                  Transfer/Interfacility/Palliative Care   \n",
       "2022-12-01       Psychiatric Problem/Abnormal Behavior/Suicide ...   \n",
       "2022-12-01                                               Discharge   \n",
       "2022-12-01                                               Discharge   \n",
       "2022-12-01                                               Discharge   \n",
       "...                                                            ...   \n",
       "2023-12-21                  Transfer/Interfacility/Palliative Care   \n",
       "2023-12-21                                               Discharge   \n",
       "2023-12-21                                               Discharge   \n",
       "2023-12-21                                               Discharge   \n",
       "2023-12-21                  Transfer/Interfacility/Palliative Care   \n",
       "\n",
       "                                     Location  \n",
       "Date of Service                                \n",
       "2022-12-01                       JACKSONVILLE  \n",
       "2022-12-01                       JACKSONVILLE  \n",
       "2022-12-01        BELLAIR-MEADOWBROOK TERRACE  \n",
       "2022-12-01        BELLAIR-MEADOWBROOK TERRACE  \n",
       "2022-12-01        BELLAIR-MEADOWBROOK TERRACE  \n",
       "...                                       ...  \n",
       "2023-12-21                       JACKSONVILLE  \n",
       "2023-12-21        BELLAIR-MEADOWBROOK TERRACE  \n",
       "2023-12-21        BELLAIR-MEADOWBROOK TERRACE  \n",
       "2023-12-21                       JACKSONVILLE  \n",
       "2023-12-21                       JACKSONVILLE  \n",
       "\n",
       "[3637 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = pd.read_csv('Trip List Edited 12.1.2022-2.1.2023.csv', parse_dates=['Date of Service'], index_col = 'Date of Service')\n",
    "data_2 = pd.read_csv('Trip List Edited 2.1.2023-4.1.2023.csv', parse_dates=['Date of Service'], index_col = 'Date of Service')\n",
    "data_3 = pd.read_csv('Trip List Edited 4.1.2023-6.1.2023.csv', parse_dates=['Date of Service'], index_col = 'Date of Service')\n",
    "data_4 = pd.read_csv('Trip List Edited 8.1.2023-12.21-2023.csv', parse_dates=['Date of Service'], index_col = 'Date of Service')\n",
    "data_current_cycle = pd.read_csv('Trip List Edited Current.csv', parse_dates=['Date of Service'], index_col = 'Date of Service')\n",
    "\n",
    "#data = pd.concat([data_1, data_2, data_3, data_4])\n",
    "data = pd.concat([data_1, data_2, data_3, data_4, data_current_cycle])\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "# with pd.option_context('display.max_rows', None,):\n",
    "#     print(data)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8108b6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit</th>\n",
       "      <th>Call Type</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Nature of Call</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date of Service</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-04-07</th>\n",
       "      <td>MEDIC 202</td>\n",
       "      <td>ALS</td>\n",
       "      <td>PRIORITY 3</td>\n",
       "      <td>Transfer/Interfacility/Palliative Care</td>\n",
       "      <td>GAINESVILLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Unit Call Type    Priority  \\\n",
       "Date of Service                                    \n",
       "2023-04-07       MEDIC 202       ALS  PRIORITY 3   \n",
       "\n",
       "                                         Nature of Call     Location  \n",
       "Date of Service                                                       \n",
       "2023-04-07       Transfer/Interfacility/Palliative Care  GAINESVILLE  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['Date of Service'] = pd.to_datetime(data['Date of Service'])\n",
    "#data.set_index('Date of Service')\n",
    "#data.sort_index()\n",
    "data['Location'] = data['Location'].str.strip()\n",
    "\n",
    "# Filtering for Jacksonville location\n",
    "data_location = data[data['Location'] == 'GAINESVILLE']\n",
    "\n",
    "# Parameters for the model and forecast\n",
    "# n_test = 14  # Number of days for testing\n",
    "\n",
    "data_location #Now has only Jacksonville locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a4fc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P3152044\\AppData\\Local\\Temp\\ipykernel_4784\\3572005536.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_location[column] = encoder.fit_transform(data_location[column])\n",
      "C:\\Users\\P3152044\\AppData\\Local\\Temp\\ipykernel_4784\\3572005536.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_location[column] = encoder.fit_transform(data_location[column])\n",
      "C:\\Users\\P3152044\\AppData\\Local\\Temp\\ipykernel_4784\\3572005536.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_location[column] = encoder.fit_transform(data_location[column])\n",
      "C:\\Users\\P3152044\\AppData\\Local\\Temp\\ipykernel_4784\\3572005536.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_location[features_to_normalize] = scaler.fit_transform(data_location[features_to_normalize])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit</th>\n",
       "      <th>Call Type</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Nature of Call</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date of Service</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-04-07</th>\n",
       "      <td>MEDIC 202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GAINESVILLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Unit  Call Type  Priority  Nature of Call     Location\n",
       "Date of Service                                                             \n",
       "2023-04-07       MEDIC 202        0.0       0.0             0.0  GAINESVILLE"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode Data\n",
    "label_encoders = {}\n",
    "for column in ['Call Type', 'Priority', 'Nature of Call']:\n",
    "    encoder = LabelEncoder()\n",
    "    data_location[column] = encoder.fit_transform(data_location[column])\n",
    "    label_encoders[column] = encoder\n",
    "\n",
    "#grouped_data = data.groupby(['Date of Service','Location', 'Unit', 'Call Type', 'Priority', 'Nature of Call']).size().reset_index(name='Daily Count')\n",
    "#grouped_data = grouped_data.sort_values(by='Date of Service')\n",
    "\n",
    "#Scaling exogenous values\n",
    "features_to_normalize = ['Call Type', 'Priority', 'Nature of Call']\n",
    "scaler = MinMaxScaler() #0 Values to represent Unit not being there for that day. \n",
    "data_location[features_to_normalize] = scaler.fit_transform(data_location[features_to_normalize]) \n",
    "data_location\n",
    "#grouped_data[features_to_normalize] = scaler.fit_transform(grouped_data[features_to_normalize])\n",
    "#grouped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5e5a08",
   "metadata": {},
   "source": [
    "The cell below uses a grid search to pick the best parameters for SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1bb2643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter space for SARIMAX\n",
    "p = d = q = range(0, 3)  # Example ranges for ARIMA orders\n",
    "P = D = Q = range(0, 3)\n",
    "s = [7, 14, 30]  #Testing for Weekly, Bi-Weely, and Monthly Seasonality\n",
    "\n",
    "# Random Grid Search across all units\n",
    "parameters = list(itertools.product(p, d, q, P, D, Q, s))\n",
    "pdq_combinations = random.sample(parameters, min(len(parameters), 6))  # Randomly sample combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fc54dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 1, 2, 1, 0, 14),\n",
       " (2, 2, 1, 1, 0, 2, 14),\n",
       " (2, 2, 1, 2, 2, 1, 14),\n",
       " (1, 2, 2, 0, 1, 2, 30),\n",
       " (2, 2, 0, 0, 0, 1, 7),\n",
       " (0, 2, 0, 2, 0, 2, 14)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdq_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb29a71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 1, 2, 1, 0, 14),\n",
       " (2, 2, 1, 1, 0, 2, 14),\n",
       " (2, 2, 1, 2, 2, 1, 14),\n",
       " (1, 2, 2, 0, 1, 2, 30),\n",
       " (2, 2, 0, 0, 0, 1, 7),\n",
       " (0, 2, 0, 2, 0, 2, 14),\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 12]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pdq_combinations = [(1, 0, 2, 2, 1, 1, 7), ] #Testing specific parameters. \n",
    "pdq_combinations.extend(((0, 0, 0, 1, 1, 1, 12),))\n",
    "pdq_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910c9074",
   "metadata": {},
   "source": [
    "Section: Used for testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "066b2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply best parameters for each unit to test\n",
    "# unit_IDs = sorted(data_location['Unit'].unique())\n",
    "\n",
    "# #Splitting training and testing by date\n",
    "# split_date = pd.Timestamp('2023-11-30')\n",
    "\n",
    "# start_date = data_location.index.min()\n",
    "# end_date = data_location.index.max()\n",
    "# date_range = pd.date_range(start= start_date, end= end_date, freq = 'D')\n",
    "# exog_data = data_location[['Call Type', 'Priority', 'Nature of Call']].groupby(data_location.index).mean().reindex(\n",
    "#                                                                                                             date_range, \n",
    "#                                                                                                             fill_value = 0)\n",
    "\n",
    "# for unit_ID in unit_IDs:\n",
    "#     print(f\"Processing Medic Unit: {unit_ID}\")\n",
    "\n",
    "#     unit_data_grouped = data_location[data_location['Unit'] == unit_ID].resample('D').count().reindex(date_range, \n",
    "#                                                                                                       fill_value = 0)\n",
    "#     unit_data_grouped = unit_data_grouped.drop('Location', axis = 1)\n",
    "#     #print(unit_data_grouped['Unit'][0])\n",
    "\n",
    "#     for i in range(len(unit_data_grouped)):\n",
    "#         if unit_data_grouped['Unit'][i] > 0:\n",
    "#             unit_data_grouped['Call Type'][i] = exog_data['Call Type'][i]\n",
    "#             unit_data_grouped['Priority'][i] = exog_data['Priority'][i]\n",
    "#             unit_data_grouped['Nature of Call'][i] = exog_data['Nature of Call'][i]\n",
    "            \n",
    "#             data_unit = unit_data_grouped['Unit']\n",
    "#             exog_unit = unit_data_grouped[['Call Type', 'Priority', 'Nature of Call']]\n",
    "            \n",
    "#     #print(exog_unit)\n",
    "    \n",
    "#     #train_end = pd.to_datetime(\"11/30/2023\")\n",
    "#     train = data_unit[data_unit.index < split_date]\n",
    "#     test = data_unit[data_unit.index >= split_date]\n",
    "\n",
    "#     train_exog = exog_unit[exog_unit.index < split_date]\n",
    "#     test_exog = exog_unit[exog_unit.index >= split_date]\n",
    "    \n",
    "#     print(data_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae571d8",
   "metadata": {},
   "source": [
    "Section: Code Testing - End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a3365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarimax_grid_search(data_location, pdq_combinations): #Aggregated order and seasonal order. \n",
    "#     best_aic = float(\"inf\")\n",
    "#     best_configuration = None\n",
    "#     best_model = None\n",
    "    \n",
    "    # Apply best parameters for each unit to test\n",
    "    unit_IDs = sorted(data_location['Unit'].unique())\n",
    "    \n",
    "    #Used for training/test split further below. \n",
    "    split_date = pd.Timestamp('2023-11-30')\n",
    "    \n",
    "    #Preparing exogenous values\n",
    "    start_date = data_location.index.min()\n",
    "    end_date = data_location.index.max()\n",
    "    date_range = pd.date_range(start= start_date, end= end_date, freq = 'D')\n",
    "    exog_data = data_location[['Call Type', 'Priority', 'Nature of Call']].groupby(data_location.index).mean().reindex(\n",
    "                                                                                                                date_range, \n",
    "                                                                                                                fill_value = 0)\n",
    "    # Initialize a dictionary to store best_configuration\n",
    "    unit_results={}\n",
    "    \n",
    "    for unit_ID in unit_IDs:\n",
    "        best_aic = float(\"inf\")\n",
    "        best_configuration = None\n",
    "        best_model = None\n",
    "        \n",
    "        print(f\"Processing Medic Unit: {unit_ID}\")\n",
    "        \n",
    "        #Using date_range from preparing exogenous values\n",
    "        unit_data_grouped = data_location[data_location['Unit'] == unit_ID].resample('D').count().reindex(date_range, \n",
    "                                                                                                          fill_value = 0)\n",
    "        unit_data_grouped = unit_data_grouped.drop('Location', axis = 1)\n",
    "        #print(unit_data_grouped['Unit'][0])\n",
    "\n",
    "        for i in range(len(unit_data_grouped)):\n",
    "            if unit_data_grouped['Unit'][i] > 0:\n",
    "                unit_data_grouped['Call Type'][i] = exog_data['Call Type'][i]\n",
    "                unit_data_grouped['Priority'][i] = exog_data['Priority'][i]\n",
    "                unit_data_grouped['Nature of Call'][i] = exog_data['Nature of Call'][i]\n",
    "        \n",
    "        data_unit = unit_data_grouped['Unit']\n",
    "        exog_unit = unit_data_grouped[['Call Type', 'Priority', 'Nature of Call']]\n",
    "        \n",
    "        #train_end = pd.to_datetime(\"11/30/2023\")\n",
    "        train = data_unit[data_unit.index < split_date]\n",
    "        test = data_unit[data_unit.index >= split_date]\n",
    "        \n",
    "        train_exog = exog_unit[exog_unit.index < split_date]\n",
    "        test_exog = exog_unit[exog_unit.index >= split_date]\n",
    "        \n",
    "        #For lesser computers.\n",
    "        for pdq in pdq_combinations:\n",
    "            try:\n",
    "                model = SARIMAX(train, order=pdq[:3], seasonal_order=pdq[3:], exog = train_exog, \n",
    "                                enforce_stationarity=False, enforce_invertibility=False)\n",
    "                model_fit = model.fit(disp=False)\n",
    "\n",
    "                if model_fit.aic < best_aic: \n",
    "                    best_aic = model_fit.aic\n",
    "                    best_configuration = pdq\n",
    "                    best_model = model_fit\n",
    "\n",
    "            except Exception as e: \n",
    "                print(f'Exception: {e}')\n",
    "                continue\n",
    "        \n",
    "        #Storing best_configuration\n",
    "        unit_results[unit_ID] = {'best_configuration' : best_configuration}\n",
    "        \n",
    "        if best_configuration is None:\n",
    "            raise ValueError(\"No suitable model parameters found for aggregate data\")\n",
    "            \n",
    "        #Predicting the rest of the forecast to compare to test data. Steps has to be the remaining days to predict. \n",
    "        predictions = best_model.forecast(steps=len(test), exog = test_exog)\n",
    "#         predictions = best_model.get_forecast(steps=len(test), exog = test_exog)\n",
    "#         forecast_values = predictions.predict_mean\n",
    "\n",
    "        # Performance Metrics\n",
    "        mse = mean_squared_error(test, predictions)\n",
    "        mae = mean_absolute_error(test, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f'Unit {unit_ID} - Best SARIMAX: {best_configuration} - MSE: {mse}, MAE: {mae}, RMSE: {rmse}')\n",
    "\n",
    "        # Plotting Forecast vs Actual\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(test, label='Actual')\n",
    "        plt.plot(predictions, label='Forecast', color='red')\n",
    "        plt.title(f'SARIMAX Model Forecast vs Actual for Unit {unit_ID}')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Unit')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "            \n",
    "    return best_aic, best_configuration, best_model, unit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f46df91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Medic Unit: MEDIC 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3747: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3747: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\P3152044\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: 'int' object is not subscriptable\n",
      "Exception: 'int' object is not subscriptable\n",
      "Exception: 'int' object is not subscriptable\n",
      "Exception: 'int' object is not subscriptable\n",
      "Exception: 'int' object is not subscriptable\n",
      "Exception: 'int' object is not subscriptable\n",
      "Exception: 'int' object is not subscriptable\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Prediction must have `end` after `start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m\n\u001b[0;32m      8\u001b[0m ts_data \u001b[38;5;241m=\u001b[39m data_location\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# exog_train = train[['Call Type', 'Priority', 'Nature of Call']]\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# exog_test = test[['Call Type', 'Priority', 'Nature of Call']]\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# #For lesser PC\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m best_aic, best_configuration, best_model, unit_results \u001b[38;5;241m=\u001b[39m sarimax_grid_search(ts_data, pdq_combinations)\n",
      "Cell \u001b[1;32mIn[9], line 74\u001b[0m, in \u001b[0;36msarimax_grid_search\u001b[1;34m(data_location, pdq_combinations)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo suitable model parameters found for aggregate data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;66;03m#Predicting the rest of the forecast to compare to test data. Steps has to be the remaining days to predict. \u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mforecast(steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test), exog \u001b[38;5;241m=\u001b[39m test_exog)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m#         predictions = best_model.get_forecast(steps=len(test), exog = test_exog)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m#         forecast_values = predictions.predict_mean\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m         \u001b[38;5;66;03m# Performance Metrics\u001b[39;00m\n\u001b[0;32m     79\u001b[0m         mse \u001b[38;5;241m=\u001b[39m mean_squared_error(test, predictions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\wrapper.py:113\u001b[0m, in \u001b[0;36mmake_wrapper.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(func(results, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), how[\u001b[38;5;241m0\u001b[39m], how[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how:\n\u001b[1;32m--> 113\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(func(results, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), how)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3537\u001b[0m, in \u001b[0;36mMLEResults.forecast\u001b[1;34m(self, steps, signal_only, **kwargs)\u001b[0m\n\u001b[0;32m   3535\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3536\u001b[0m     end \u001b[38;5;241m=\u001b[39m steps\n\u001b[1;32m-> 3537\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnobs, end\u001b[38;5;241m=\u001b[39mend, signal_only\u001b[38;5;241m=\u001b[39msignal_only,\n\u001b[0;32m   3538\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3487\u001b[0m, in \u001b[0;36mMLEResults.predict\u001b[1;34m(self, start, end, dynamic, information_set, signal_only, **kwargs)\u001b[0m\n\u001b[0;32m   3422\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3423\u001b[0m \u001b[38;5;124;03mIn-sample prediction and out-of-sample forecasting\u001b[39;00m\n\u001b[0;32m   3424\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3484\u001b[0m \u001b[38;5;124;03m    including confidence intervals.\u001b[39;00m\n\u001b[0;32m   3485\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3486\u001b[0m \u001b[38;5;66;03m# Perform the prediction\u001b[39;00m\n\u001b[1;32m-> 3487\u001b[0m prediction_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_prediction(\n\u001b[0;32m   3488\u001b[0m     start, end, dynamic, information_set\u001b[38;5;241m=\u001b[39minformation_set,\n\u001b[0;32m   3489\u001b[0m     signal_only\u001b[38;5;241m=\u001b[39msignal_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction_results\u001b[38;5;241m.\u001b[39mpredicted_mean\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3340\u001b[0m, in \u001b[0;36mMLEResults.get_prediction\u001b[1;34m(self, start, end, dynamic, information_set, signal_only, index, exog, extend_model, extend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   3336\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3338\u001b[0m \u001b[38;5;66;03m# Handle start, end, dynamic\u001b[39;00m\n\u001b[0;32m   3339\u001b[0m start, end, out_of_sample, prediction_index \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 3340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_get_prediction_index(start, end, index))\n\u001b[0;32m   3342\u001b[0m \u001b[38;5;66;03m# Handle `dynamic`\u001b[39;00m\n\u001b[0;32m   3343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dynamic, (\u001b[38;5;28mstr\u001b[39m, dt\u001b[38;5;241m.\u001b[39mdatetime, pd\u001b[38;5;241m.\u001b[39mTimestamp)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836\u001b[0m, in \u001b[0;36mTimeSeriesModel._get_prediction_index\u001b[1;34m(self, start, end, index, silent)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;124;03mGet the location of a specific key in an index or model row labels\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;124;03msince we have required them to be full indexes, there is no ambiguity).\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    835\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog)\n\u001b[1;32m--> 836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_prediction_index(\n\u001b[0;32m    837\u001b[0m     start,\n\u001b[0;32m    838\u001b[0m     end,\n\u001b[0;32m    839\u001b[0m     nobs,\n\u001b[0;32m    840\u001b[0m     base_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index,\n\u001b[0;32m    841\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    842\u001b[0m     silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[0;32m    843\u001b[0m     index_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_none,\n\u001b[0;32m    844\u001b[0m     index_generated\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_generated,\n\u001b[0;32m    845\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m    846\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:389\u001b[0m, in \u001b[0;36mget_prediction_index\u001b[1;34m(start, end, nobs, base_index, index, silent, index_none, index_generated, data)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# Validate prediction options\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m<\u001b[39m start:\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction must have `end` after `start`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    391\u001b[0m \u001b[38;5;66;03m# Handle custom prediction index\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# First, if we were given an index, check that it's the right size and\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# use it if so\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Prediction must have `end` after `start`."
     ]
    }
   ],
   "source": [
    "# #Running Grid Search\n",
    "# #SARIMAX can internally difference with value (d). We manually difference (d=1) just to check stationarity. \n",
    "# #Now we will let SARIMAX integrate difference by setting d=1 manually on the ORIGINAL dataset. \n",
    "\n",
    "#ts_data = df['Actual Trips']\n",
    "#ts_data = train['Unit']\n",
    "\n",
    "ts_data = data_location\n",
    "\n",
    "# exog_train = train[['Call Type', 'Priority', 'Nature of Call']]\n",
    "# exog_test = test[['Call Type', 'Priority', 'Nature of Call']]\n",
    "\n",
    "# #For lesser PC\n",
    "best_aic, best_configuration, best_model, unit_results = sarimax_grid_search(ts_data, pdq_combinations)\n",
    "\n",
    "#print(f\"Best SARIMAX parameters: {best_configuration} with AIC: {best_aic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71902824",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_configuration #You can interupt cell above to get the current best_params value without having to finish all the calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = unit_results['MEDIC 203'].values()\n",
    "results = list(best_config)\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126079f1",
   "metadata": {},
   "source": [
    "Everything below is to generate future values. (Needs to be reworked.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e556d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The best parameters for all Units combined; Unit MEDIC 1 usually has highest RSME so minimizing this\n",
    "    #Best SARIMAX: (0, 0, 0, 2, 0, 1, 7) - MSE: 3.477645430848429, MAE: 1.3565603776833444, RMSE: 1.8648446130571\n",
    "\n",
    "unique_locations = data['Location'].unique()\n",
    "print(\"Unique Locations:\", unique_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the filtering condition based on the actual string in your dataset\n",
    "data_location = data[data['Location'] == 'GAINESVILLE']\n",
    "\n",
    "# Get unique 'Medic Units' \n",
    "unit_IDs = data_location['Unit'].unique()\n",
    "unit_IDs = sorted(unit_IDs)\n",
    "print(\"Unique Units in Gainesville:\", unit_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85445485",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique Vehicle IDs in Gainesville:\", unit_IDs)\n",
    "\n",
    "#Preparing exogenous values\n",
    "#Using date_range from preparing exogenous values\n",
    "start_date = data_location.index.min()\n",
    "end_date = data_location.index.max()\n",
    "date_range = pd.date_range(start= start_date, end= end_date, freq = 'D')\n",
    "\n",
    "models = {} #Fitting model for all units individually.\n",
    "for unit_ID in unit_IDs:\n",
    "    print(f\"Processing Call Type: {unit_ID}\")\n",
    "\n",
    "    # Aggregate data by day for each 'Unit'\n",
    "    ts = data_location[data_location['Unit'] == unit_ID].resample('D').count().reindex(date_range, fill_value = 0)\n",
    "    ts = ts.drop('Location', axis = 1)\n",
    "    ts_data = ts['Unit']\n",
    "    \n",
    "    #print(f\"Sample Data for {unit_ID}:\\n\", ts.head())  # Print sample data\n",
    "    #Retrieve best_configuration for current unit\n",
    "    results = unit_results[unit_ID].values()\n",
    "    results = list(results)\n",
    "    best_configuration = results[0]\n",
    "    \n",
    "    # Check if time series is not empty\n",
    "    if not ts.empty:\n",
    "        model = SARIMAX(ts_data, order=best_configuration[:3], seasonal_order=best_configuration[3:], #exog = train_exog, #Implementing later\n",
    "                       enforce_stationarity=False, enforce_invertibility=False) \n",
    "        models[unit_ID] = model.fit(disp=True)\n",
    "    else:\n",
    "        print(f\"No data available for Call Type: {unit_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6cdde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = {}\n",
    "steps = 14\n",
    "for unit_ID, model in models.items():\n",
    "    forecasts[unit_ID] = model.forecast(steps)  # Forecasting for the next day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1fe2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# Determine the date for the forecast\n",
    "# Assuming you are forecasting for the next day after the last date in your data\n",
    "last_date = data.index.max()\n",
    "start_forecast_date = last_date + timedelta(days=1)\n",
    "\n",
    "# Initialize a dictionary to store forecasts for each date\n",
    "date_forecasts = {start_forecast_date + timedelta(days=i): [] for i in range(steps)}\n",
    "\n",
    "# Generate and store forecasts for each call type and each date\n",
    "for unit_ID in unit_IDs:\n",
    "    model = models.get(unit_ID)\n",
    "    if model:\n",
    "        forecast_values = model.forecast(steps=steps)\n",
    "        forecast_values = abs(forecast_values)\n",
    "        for i in range(steps):\n",
    "            forecast_date = start_forecast_date + timedelta(days=i)\n",
    "            # Append the forecast string for each call type and date\n",
    "            #date_forecasts[forecast_date].append(f\"{forecast_values[i]:.0f} calls of type '{vehicle_ID}'\")\n",
    "            #date_forecasts[forecast_date].append(f\"{vehicle_ID}: {forecast_values[i]:.0f}\")\n",
    "            date_forecasts[forecast_date].append(f\"{unit_ID}: {forecast_values[i]:.0f}\")\n",
    "    else:\n",
    "        # Handle case where there is no model for a call type\n",
    "        for date in date_forecasts:\n",
    "            date_forecasts[date].append(f\"0 calls for unit '{unit_ID}'\")\n",
    "\n",
    "# Print the combined forecast message for each date\n",
    "for date, forecasts in date_forecasts.items():\n",
    "    forecast_message = \" \\n\".join(forecasts)\n",
    "    print(f\"There will be: \\n{forecast_message}\\nin the location of Gainesville {date.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e178c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating an empty DataFrame with specified columns\n",
    "#forecast_results_df = pd.DataFrame(columns=['Date of Service', 'Call Type & Volume', 'Location'])\n",
    "\n",
    "# Initialize a list to store forecast data for DataFrame\n",
    "forecast_data = []\n",
    "\n",
    "#Generate forecast data suitable for DataFrame\n",
    "for date, forecasts in date_forecasts.items():\n",
    "    #forecast_message = \" and \".join(forecasts)\n",
    "    forecast_message = ' , '.join(forecasts)\n",
    "    forecast_data.append({\n",
    "        \"Date of Service\": date.strftime('%A: %m-%d-%Y'),\n",
    "        \"Unit\": forecast_message,\n",
    "        \"Location\": \"Gainesville  # or dynamically set location if needed\n",
    "    })\n",
    "    \n",
    "# Create a DataFrame\n",
    "forecast_df = pd.DataFrame(forecast_data)\n",
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output file path\n",
    "output_file_path = 'Model Forecast Results.csv'\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "try:\n",
    "    forecast_df.to_csv(output_file_path, mode='a', index=False, header=False)\n",
    "    success = True\n",
    "except Exception as e:\n",
    "    success = False\n",
    "    error_message = str(e)\n",
    "\n",
    "# Returning the path if successful, else the error message\n",
    "output_file_path if success else error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043cd3de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
